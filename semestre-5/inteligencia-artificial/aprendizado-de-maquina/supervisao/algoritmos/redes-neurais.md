# Redes neurais

## Perceptron

As redes neurais usam um modelo computacional de neur√¥nio chamado&#x20;Perceptron. Ele √© uma estrutura inspirada em um neur√¥nio (entrada de sinal e ativa√ß√£o), que resulta em **zero ou um**, que tenta <mark style="color:blue;">decidir se uma entrada pertence a uma classe ou n√£o</mark>.

{% hint style="success" %}
A explica√ß√£o formal para um perceptron √©: neur√¥nio artificial que possui entrada de dados, fun√ß√£o de ativa√ß√£o, peso e vi√©s (com soma ponderada). A <mark style="color:purple;">fun√ß√£o de ativa√ß√£o</mark> √© o que vai ser passado adiante.&#x20;
{% endhint %}

Essas entradas s√£o vari√°veis de um dado (idade, peso, etc) e cada uma delas tem um peso que simboliza a import√¢ncia dessa entrada, chamado de `Wi` e come√ßando com **valores aleat√≥rios**. As entradas s√£o somadas com esse peso e se essa soma atingir um certo valor, resulta em um e se for menor, a sa√≠da ser√° zero. Essa f√≥rmula √© respons√°vel por essa representa√ß√£o:

$$
ùë¶ = ùëì (‚àë ùëäùëñ ‚àó ùëãùëñ + ùëäùëè ‚àó 1)
$$

<details>

<summary>Explica√ß√£o da f√≥rmula</summary>

* f() uma [fun√ß√£o degrau](#user-content-fn-1)[^1], for√ßando o resultado a ser 0 ou 1.
* ùëäùëè  &#x20;√© um peso para uma entrada especial que ser√° discutida em breve.
* A parte interna √© uma soma ponderada das entradas, da mesma forma descrita acima.

</details>

Essa f√≥rmula gera <mark style="color:blue;">**uma reta**</mark> no plano cartesiano:

* Ao alterar o peso Wb, a angulatura desta reta se altera.
* Ao alterar o vi√©s[^2], mudamos por onde a reta passa. Caso contr√°rio, ela passa pela origem (0,0).

<figure><img src="../../../../../.gitbook/assets/image (1).png" alt="" width="263"><figcaption></figcaption></figure>

Essa linha √© usada para separar os grupos em seus cortes. Alteraramos o peso ou o vi√©s para ir ajustando as linhas e fazer cortes precisos na separa√ß√£o dos grupos. Em resumo, <mark style="color:blue;">cada linha √© um neur√¥nio/perceptron</mark>.

Muitas vezes n√£o √© poss√≠vel dividir os grupos com apenas uma linha como em problemas do tipo XOR, ent√£o podemos usar o modelo MLP de redes neurais, que utiliza mais linhas para criar novas divis√µes. Curiosidade: n√£o pensar em usar duas linhas foi o que travou o desenvolvimento da IA a muitos anos atr√°s.

### Gradiente descendente

Como dito, os pesos come√ßam com valores aleat√≥rios ent√£o devem ser ajustados usando gradiente descendente, um mecanismo que ajuda o perceptron a aprender que faz as seguintes a√ß√µes:

1. Calcula a sa√≠da.
2. Compara com o valor real.
3. Calcula o erro.
4. **Atualiza os pesos para reduzir o erro**.

Ap√≥s fazer uma previs√£o, pode-se medir o erro comparando a sa√≠da prevista com o valor real (r√≥tulo). Toda vez que o modelo erra, o gradiente descendente entra em a√ß√£o para corrigir/minizar o erro. Com aplica√ß√£o tipo `batch`, ele √© aplicado ap√≥s todos os dados de treino (mais est√°vel por√©m mais lento).

#### Erro em fun√ß√£o do peso

O erro √© uma curva que parece uma par√°bola em um gr√°fico, onde consequentemente o menor erro fica no ponto mais em baixo que √© a descida (por isso chamado de descendente).

<figure><img src="../../../../../.gitbook/assets/image (5).png" alt=""><figcaption></figcaption></figure>

A derivada da fun√ß√£o do erro consegue resgatar a inclina√ß√£o da reta naquele ponto e nisso podemos concluir para onde temos que andar, pois a derivada √© zero no ponto m√≠nimo e derivadas zero formam uma reta totalmente horizontal. Portanto, se a reta tem alguma inclina√ß√£o:

* Baixo: quer dizer que precisamos avan√ßar o ponto.
* Cima: quer dizer que precisamos recuar o ponto.

<figure><img src="../../../../../.gitbook/assets/image (8).png" alt=""><figcaption></figcaption></figure>

#### Fator de aprendizado

Vendo que precisamos mover o peso para atingir o menor erro, o fator de aprendizado √© o tamanho do passo dado at√© a descida. Passos muito largos vai fazer com que sempre passe o menor ponto e passos curtos vai custar na otimiza√ß√£o do algoritmo.

Esse √© um exemplo final de perceptron fazendo divis√£o de grupos:

<figure><img src="../../../../../.gitbook/assets/image (2).png" alt="" width="309"><figcaption></figcaption></figure>

## Perceptron Multi Camadas (MLP)

Usa mais de um perceptron para conseguir fazer divis√µes precisas, onde <mark style="color:blue;">cada perceptron √© respons√°vel por uma regi√£o espec√≠fica</mark>. O conceito de ter entrada de dados processadas em camadas gera o conceito de redes neurais. A MLP √© definida quando todos os perceptrons e entradas est√£o conectados com todos os outros da camada anterior e posterior.

A rede ser√° formada por tr√™s camadas, cada camada representada por uma cor, e os c√≠rculos s√£o os neur√¥nios. Significa que podemos ter infinitos neur√¥nios por camada, mas as camadas podem ter suas limita√ß√µes:

* Camada de entrada: N√£o h√° neur√¥nios, apenas as entradas de dados e o total √© o n√∫mero de features[^3]. Eles s√≥ repassam o dado e s√≥ pode haver uma √∫nica camada de entrada.
* Camada de sa√≠da: O n√∫mero de neur√¥nios √© o n√∫mero de classes que podem haver nos r√≥tulos. Tamb√©m apenas uma camada.
* Camada escondida: N√£o existem restri√ß√µes para a quantidade de camadas escondidas e nem de neur√¥nios, depende das transforma√ß√µes a serem feitas.

<figure><img src="../../../../../.gitbook/assets/image (9).png" alt=""><figcaption></figcaption></figure>

### Fun√ß√£o dos neur√¥nios

Cada neur√¥nio √© como se fosse um aluno em um projeto: tem a sua respectiva fun√ß√£o. Um neur√¥nio fica respons√°vel por detectar c√≠rculos e outro por retas. Esses neur√¥nios precisam da ajuda do neur√¥nio de sa√≠da para detectar que essas formas s√£o na verdade um rosto, pois a camada de sa√≠da ajusta os pesos com <mark style="color:purple;">backpropagation</mark>.

Ent√£o a camada de sa√≠da agora faz a predi√ß√£o e compara com o resultado final, calculando um erro. Esse erro √© propagado no caminho de volta, fazendo com que o gradiente descendente ajuste seus devidos pesos (baseado no erro de toda a rede).&#x20;

### Varia√ß√£o de par√¢metros

A varia√ß√£o da camada escondida ajuda na detec√ß√£o de padr√µes, mas tem que tomar cuidado com o overfitting. Esses n√∫meros representam quantos neur√¥nios em cada camada escondida, ent√£o n√∫meros agregados quer dizer mais de uma camada.

Quanto mais camadas, maior a chance de aprender fun√ß√µes n√£o lineares complexas. A diminui√ß√£o de valores √© para criar um fun√≠l for√ßando o algoritmo a resumir as informa√ß√µes. Quanto mais camadas, mais dados s√£o requeridos.

```python
'hidden_layer_sizes': [
    (200,), (100,), (50,), (200,100), (200,100,50), (200,100,50,25)
]
```

As fun√ß√µes de ativa√ß√£o dos perceptrons em redes neurais n√£o se limitam apenas no bin√°rio zero e um (aquelas chamadas de fun√ß√£o degrau). Essas fun√ß√µes retornam valores cont√≠nuos. A fun√ß√£o `relu` √© a mais usada por ser eficiente e funcionar como `max(0, x)`. J√° a `tanh` suaviza os dados retornando entre -1 e 1.

```python
'activation': ['relu', 'tanh']
```

Os par√¢metros `solver` + `learning_rate_init` + `alpha` servem para a atualiza√ß√£o dos pesos.

* Solver: algoritmo usado para fazer o gradiente descendente, definindo como o erro √© corrigido.&#x20;
  * `'adam'`: adaptativo, ajusta o aprendizado ao longo do tempo, muito usado hoje.
  * `'sgd'`: gradiente estoc√°stico puro. Mais lento, mas mais simples e te d√° mais controle.
* Alpha: n√£o varia, deixando um valor bem baixo que faz penalidades leves para os pesos.
* Learning rate init: √â o tamanho dos passos dados para o gradiente descendente. Lembrando que existe aquele dilema entre valores altos e baixos.

```python
'solver': ['adam', 'sgd'],
'alpha': [0.0001],
'learning_rate_init': [0.001, 0.01, 0.1]
```

Podemos definir a cada quantas amostras de treino o algoritmo vai fazer a atualiza√ß√£o dos pesos. O algoritmo passa por todas as camadas e faz todo o seu percurso, mas usando a quantidade definida de amostras em `batch_size`. Quanto maior, mais est√°vel.

```python
'batch_size': [8, 16, 32, 64]
```

Por fim, algo j√° visto em valida√ß√£o, o embaralhamento de dados a [cada √©poca](#user-content-fn-4)[^4] para evitar decorar ordem de dados com shuffle. N√£o embaralhar pode ser bom para dados que podem ser afetados por sequ√™ncias temporais.

```python
'shuffle': [True, False]
```

### Aplica√ß√£o do resto do algoritmo

Define o m√°ximo de √©pocas. 1000 significa que o modelo pode passar at√© mil vezes pelos dados de treino, mas se convergir antes, o modelo vai parar. Convergir significa que em X itera√ß√µes (podendo ser definido no par√¢metro n\_iter\_no\_change) n√£o ter melhora significativa no F1-score, o modelo √© interrompido automaticamente.&#x20;

```python
mlp = MLPClassifier(
    max_iter=1000,
    early_stopping=True,
    random_state=42
)

grid_search_mlp = GridSearchCV(
    estimator=mlp,
    param_grid=param_grid_mlp,
    scoring='f1_weighted',
    cv=5,      # usa valida√ß√£o cruzada com 5 folds para avaliar a performance
    verbose=1, # usa todos os n√∫cleos do processador
    n_jobs=-1  # imprime progresso no terminal
)
grid_search_mlp.fit(X_train, y_train)
```

[^1]: Retorna zero ou um.

[^2]: Sinal/dendrito do neur√¥nio, que √© constantemente igual a 1 e estar√° associado a um    &#x20;peso ùëäb.

[^3]: Colunas da base de dados sem contar o r√≥tulo.

[^4]: Ciclo completo de treino.
