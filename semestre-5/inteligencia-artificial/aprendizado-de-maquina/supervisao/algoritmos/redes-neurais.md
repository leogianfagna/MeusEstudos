# Redes neurais

Uma rede neural √© um mecanismo de aprendizado que imita como um c√©rebro humano aprende. O c√©rebro recebe o est√≠mulo do mundo exterior, faz o processamento e gera o resultado. √Ä medida que a tarefa se torna complicada, v√°rios neur√¥nios formam uma rede complexa, transmitindo informa√ß√µes entre si. Portanto, a rede neural artificial imita um comportamento semelhante.

## Perceptron

As redes neurais usam um modelo computacional de neur√¥nio chamado&#x20;Perceptron. Ele √© uma estrutura inspirada em um neur√¥nio (entrada de sinal e ativa√ß√£o), que resulta em **zero ou um**, que tenta <mark style="color:blue;">decidir se uma entrada pertence a uma classe ou n√£o</mark>.

{% hint style="success" %}
A explica√ß√£o formal para um perceptron √©: neur√¥nio artificial que possui entrada de dados, fun√ß√£o de ativa√ß√£o, peso e vi√©s (com soma ponderada). A <mark style="color:purple;">fun√ß√£o de ativa√ß√£o</mark> √© o que vai ser passado adiante.&#x20;
{% endhint %}

Essas entradas s√£o vari√°veis de um dado (idade, peso, etc) e cada uma delas tem um peso que simboliza a import√¢ncia dessa entrada, chamado de `Wi` e come√ßando com **valores aleat√≥rios**. As entradas s√£o somadas com esse peso e se essa soma atingir um certo valor, resulta em um e se for menor, a sa√≠da ser√° zero. Essa f√≥rmula √© respons√°vel por essa representa√ß√£o:

$$
ùë¶ = ùëì (‚àë ùëäùëñ ‚àó ùëãùëñ + ùëäùëè ‚àó 1)
$$

<details>

<summary>Explica√ß√£o da f√≥rmula</summary>

* f() uma [fun√ß√£o degrau](#user-content-fn-1)[^1], for√ßando o resultado a ser 0 ou 1.
* ùëäùëè  &#x20;√© um peso para uma entrada especial que ser√° discutida em breve.
* A parte interna √© uma soma ponderada das entradas, da mesma forma descrita acima.

</details>

Essa f√≥rmula gera <mark style="color:blue;">**uma reta**</mark> no plano cartesiano:

* Ao alterar o peso Wb, a angulatura desta reta se altera.
* Ao alterar o vi√©s[^2], mudamos por onde a reta passa. Caso contr√°rio, ela passa pela origem (0,0).

<figure><img src="../../../../../.gitbook/assets/image (1) (2).png" alt="" width="263"><figcaption></figcaption></figure>

Essa linha √© usada para separar os grupos em seus cortes. Alteraramos o peso ou o vi√©s para ir ajustando as linhas e fazer cortes precisos na separa√ß√£o dos grupos. Em resumo, <mark style="color:blue;">cada linha √© um neur√¥nio/perceptron</mark>.

Muitas vezes n√£o √© poss√≠vel dividir os grupos com apenas uma linha como em problemas do tipo XOR, ent√£o podemos usar o modelo MLP de redes neurais, que utiliza mais linhas para criar novas divis√µes. Curiosidade: n√£o pensar em usar duas linhas foi o que travou o desenvolvimento da IA a muitos anos atr√°s.

## Perceptron Multi Camadas (MLP)

Usa mais de um perceptron (ou chamamos de neur√¥nio artificial) para conseguir fazer divis√µes precisas, onde <mark style="color:blue;">cada perceptron √© respons√°vel por uma regi√£o espec√≠fica</mark>. O conceito de ter entrada de dados processadas em camadas gera o conceito de redes neurais. A MLP √© definida quando todos os perceptrons e entradas est√£o conectados com todos os outros da camada anterior e posterior.

A rede ser√° formada por tr√™s camadas, cada camada representada por uma cor, e os c√≠rculos s√£o os neur√¥nios:

* Camada de entrada: N√£o h√° neur√¥nios, apenas as entradas de dados e o total √© o n√∫mero de features[^3]. Eles s√≥ repassam o dado e s√≥ pode haver uma √∫nica camada de entrada.
* Camada de sa√≠da: O n√∫mero de neur√¥nios √© o n√∫mero de classes que podem haver nos r√≥tulos. Tamb√©m apenas uma camada.
* Camada escondida: N√£o existem restri√ß√µes para a quantidade de camadas escondidas e nem de neur√¥nios, depende das transforma√ß√µes a serem feitas.

<figure><img src="../../../../../.gitbook/assets/image (9).png" alt=""><figcaption></figcaption></figure>

### Fun√ß√£o dos neur√¥nios

Cada neur√¥nio √© como se fosse um aluno em um projeto: tem a sua respectiva fun√ß√£o. Um neur√¥nio fica respons√°vel por detectar c√≠rculos e outro por retas.&#x20;

Os neur√¥nios fazem transforma√ß√£o linear na entrada (a f√≥rmula mostrada no perceptron), que √© a combina√ß√£o ponderada das entradas somado com o vi√©s. Recapitulando, uma transforma√ß√£o linear resulta em uma reta, n√£o podendo separar grupos complexos. Para conseguir uma transforma√ß√£o n√£o linear, esse resultado √© passado para uma <mark style="color:purple;">fun√ß√£o de ativa√ß√£o</mark>.

### Fun√ß√£o de ativa√ß√£o

A fun√ß√£o de ativa√ß√£o pega o resultado da transforma√ß√£o linear (chamamos de `z`) e joga em sua pr√≥pria f√≥rmula. Essa transforma√ß√£o n√£o linear √© capaz de criar retas e curvas. Ela <mark style="color:blue;">resulta em um dado matem√°tico, usado para passar informa√ß√£o adiante</mark> e que seu significado [depende do tipo de fun√ß√£o ativa√ß√£o utilizado](#user-content-fn-4)[^4].

Se esse neur√¥nio estiver na camada de sa√≠da, esse resultado matem√°tico √© a sa√≠da da rede (a predi√ß√£o). Esse valor de sa√≠da ser√° comparado com o valor real, calculando um erro, seguindo para o passo de <mark style="color:purple;">backpropagation</mark>.

<figure><img src="../../../../../.gitbook/assets/image (1) (1).png" alt=""><figcaption></figcaption></figure>

#### Fun√ß√£o de etapa bin√°ria

Essa fun√ß√£o √© apenas para aprender teoria, que √© a fun√ß√£o usada no modelo do Perceptron no surgimento dele. √â uma fun√ß√£o que resulta em zero ou um, criando uma fun√ß√£o degrau. Por isso que elas n√£o conseguem resolver problemas n√£o linearmente separ√°veis, pois s√£o retas.

A derivada de uma fun√ß√£o degrau √© zero, pois n√£o h√° inclina√ß√£o. Por conta disso, a fun√ß√£o degrau n√£o fornece gradiente √∫til, e como o gradiente √© a base matem√°tica para o ajuste dos pesos durante o treinamento, redes modernas usam gradiente cont√≠nuo e √∫til.

#### Fun√ß√£o linear `identity`

√â raramente usada em camadas ocultas, pois a derivada de uma fun√ß√£o linear √© uma constante. Isso quer dizer que o gradiente seria o mesmo em todo o backpropagation. Se o gradiente √© o mesmo, n√£o teremos melhora no erro.

Ent√£o a sa√≠da com essa fun√ß√£o √© uma transforma√ß√£o linear da entrada, o que pode ser √∫til para algoritmos simples de separa√ß√£o linear.

#### Sigm√≥ide `logistic`

Essa fun√ß√£o amplamente utilizada varia dos valores de zero a um e faz um formato de S, que pode ser entendida como o fato de tentar empurrar os valores resultantes para a extremidade, o que facilita a identifica√ß√£o de classes. Portanto, lembra a fun√ß√£o bin√°ria mas n√£o √© linear e existe sim seu gradiente.

O problema dessa fun√ß√£o √© que ela pode tornar o gradiente muito pequeno quando o valor est√° muito pr√≥ximo de zero ou um (pois √© um S e quase n√£o tem inclina√ß√µes). O gradiente que √© um fator de 3 valores incluindo a fun√ß√£o ativa√ß√£o, se multiplicado a uma fun√ß√£o ativa√ß√£o muito baixa, consequentemente se torna pequeno.

O problema do gradiente baixo √© que ele n√£o √© capaz de ajustar pesos (gradiente baixo ‚â† erro baixo). Com o gradiente baixo, o erro n√£o muda muito mesmo ajustando os pesos. Veja matematicamente:

> Erro = 12
>
> Wnovo = (w - n) \* gradiente
>
> Deltaw = (0.1) \* 0.00001 = 0.000001 -> Veja que o peso n√£o mudou quase nada.

#### Tanh `tanh`

Funciona de forma igual √† sigm√≥ide mas deixa sim√©trico em rela√ß√£o √† origem, ent√£o varia de -1 at√© 1, resolvendo o problema dos valores n√£o podendo ser negativos.

N√£o ter negativos pode ser um problema. A possibilidade de poder ter resultados negativos permite que os pesos possam se ajustar de forma livre, para cima ou para baixo dependendo da dire√ß√£o do erro. Al√©m disso, ter um intervalo menor ajuda no problema de gradientes pequenos, o que tamb√©m s√£o chamados de vanishing gradients.

#### ReLu `relu`

√â a fun√ß√£o mais popular atualmente, pois o fluxo matem√°tico dela favorece os gradientes e √© bem simples: se o resultado dessa fun√ß√£o ativa√ß√£o for negativo, a derivada da relu ser√° `0` e caso contr√°rio ser√° exatamente igual a `1`.

O valor de zero vai inibir que neur√¥nios irrelevantes participem do aprendizado, evitando perda de tempo ajustando peso de neur√¥nios mortos. E quando est√° na parte positiva, n√£o atrapalha o gradiente pois ele √© igual a 1 e qualquer coisa multiplicada a 1 d√° ele mesmo.&#x20;

<figure><img src="../../../../../.gitbook/assets/image (1).png" alt=""><figcaption></figcaption></figure>

O gradiente sendo igual a 1 indica ser muito mais forte e permite um fluxo mais saud√°vel no backpropagation.

### Backpropagation

durante o backpropagation, as atualiza√ß√µes dos pesos s√£o influenciadas pelo gradiente da fun√ß√£o de ativa√ß√£o.



### Gradiente descendente

Cada neur√¥nio tem a sua entrada de pesos e a modifica√ß√£o de pesos vai alterar o erro da rede (a tal fun√ß√£o de perda). Ou seja, alterar os pesos corretamente v√£o fazer com que o erro melhore e o modelo aprenda.

Agora que temos o valor desse erro, calculado nos neur√¥nios de sa√≠da, o gradiente descendente √© o m√©todo para <mark style="color:blue;">ajustar os pesos da entrada para minimizar esse erro</mark>. Ele √© executado dentro de cada neur√¥nio, pois o gradiente √© a <mark style="color:blue;">derivada da fun√ß√£o de perda em rela√ß√£o ao peso respectivo daquele neur√¥nio</mark>. Mas o que esse valor quer dizer?

!!! IMAGEM DO aL/aW (se mudar isso, vai afetar isso)

A fun√ß√£o de perda (erro total da rede) √© um gr√°fico de uma curva que remete a uma par√°bola, onde consequentemente o menor erro fica no ponto mais em baixo que √© a descida (por isso chamado de descendente). Podemos achar esse erro pois a derivada no menor ponto √© igual a zero.

<figure><img src="../../../../../.gitbook/assets/image (5).png" alt=""><figcaption></figcaption></figure>

O resultado de gradiente descendente √© um n√∫mero que <mark style="color:blue;">indica a inclina√ß√£o do ponto atual do peso</mark> em rela√ß√£o a essa curva. Sabendo dessa inclina√ß√£o, sabemos qual a dire√ß√£o que o ponto precisa caminhar para alcan√ßar a derivada zero, que √© o ponto m√≠nimo. A derivada √© zero pois no ponto m√≠nimo ela forma uma reta. Portanto, se a reta tem alguma inclina√ß√£o:

* Baixo: quer dizer que precisamos avan√ßar o ponto.
* Cima: quer dizer que precisamos recuar o ponto.

<figure><img src="../../../../../.gitbook/assets/image (8).png" alt="" width="563"><figcaption></figcaption></figure>

Sabendo dessa dire√ß√£o, o ponto vai caminhar. O modelo vai resgatar o learning rate, que √© o tamanho do passo, e andar um montante em dire√ß√£o ao ponto de inflex√£o, o que tamb√©m significa ajustar o peso.

<figure><img src="../../../../../.gitbook/assets/image (14).png" alt=""><figcaption></figcaption></figure>

!!! IMAGEM ANDANDO NO GR√ÅFICO

Ent√£o esse peso foi ajustado. Se o peso mudou, segue em frente com a rede neural (o mesmo ciclo inicial), at√© chegar nas camadas de sa√≠da, gerar um novo erro e repetir esse processo novamente. Basicamente, o gradiente responde depois do backpropagation: se eu mudar um pouco este peso, o erro da rede vai aumentar ou diminuir? E quanto?

!!! IMAGEM DO GR√ÅFICO DO MEU PAPEL, aL/aW = 0

{% hint style="info" %}
## Matematicamente falando

Matematicamente, o gradiente envolve a derivada da fun√ß√£o de perda, derivada da ativa√ß√£o, e derivada da transforma√ß√£o linear (pelo peso).
{% endhint %}

#### Solver

Decide como aplicar o gradiente descendente, mas independente das formas, usam o valor resultado pelo c√°lculo do gradiente, o que muda √© o depois.

* SGD (Stochastic Gradient Descent) √© o m√©todo cl√°ssico e tradicional, visto acima.
* ADAM √© um modelo que ajusta o learning rate.

O m√©todo ADAM √© menos sens√≠vel √† escolha do learning rate. Seu principal trabalho √© ajustar o fator de aprendizagem baseado no contexto. Ele √© um dos modelos mais usados por ser muito mais r√°pido, j√° que ajusta, fica mais r√°pido de convergir.

O learning rate base n√£o √© alterado, ele inicia naquele valor e modula automaticamente os tamanhos do passo. Esse ajuste √© para cada peso individualmente. Com uma l√≥gica b√°sica, se o gradiente for est√°vel vai aumentando o passo e ser for inst√°vel diminui.

Basicamente, ajusta baseado no passo que deveria dar. E ele faz isso usando m√©dias: hist√≥rico da m√©dia dos gradientes e a vari√¢ncia desse hist√≥rico.

#### Fator de aprendizado

Vendo que precisamos mover o peso para atingir o menor erro, o fator de aprendizado √© o tamanho do passo dado at√© a descida. Passos muito largos vai fazer com que sempre passe o menor ponto e passos curtos vai custar na otimiza√ß√£o do algoritmo.

Esse √© um exemplo final de perceptron fazendo divis√£o de grupos:

<figure><img src="../../../../../.gitbook/assets/image (2) (2).png" alt="" width="309"><figcaption></figcaption></figure>

### Batch size

O **batch size** define a quantidade de amostras que a rede neural processa antes de realizar uma atualiza√ß√£o dos pesos durante o treinamento. Em vez de calcular o gradiente e ajustar os pesos ap√≥s cada exemplo individual, o modelo agrupa um n√∫mero espec√≠fico de exemplos (o batch), calcula a m√©dia da perda e dos gradientes sobre esse grupo, e s√≥ ent√£o atualiza os pesos.

Isso ajuda a equilibrar o custo computacional e a estabilidade do treinamento, permitindo que o modelo fa√ßa atualiza√ß√µes mais frequentes (se o batch for pequeno) ou gradientes mais est√°veis (se o batch for maior), controlando a velocidade e a qualidade do aprendizado.

O segundo batch inicia com os pesos calculados para o primeiro batch. Ent√£o o segundo batch vai para as camadas de entrada com os pesos calculados para o batch 1 e assim sucessivamente. Um batch n√£o se junta com o outro.

O `max_iter` s√£o os ciclos/√©pocas. Significa quantas vezes o processo **completo** ir√° se repetir at√© ser encerrado, ou se convergir primeiro com `early_stopping`. Se temos 100 `batchs` e 1000 `max_iter`:

* Isso quer dizer que vamos mandar o batch 1 at√© o 100, isso ser√° o max\_iter 1 ou primeiro ciclo.
* Repetir esse MESMO processo, iniciando do batch, mais 999 vezes.

### Regulariza√ß√£o

Representado pelo par√¢metro alpha Œ± √© uma t√©cnica para combater overfitting.&#x20;

### Aplica√ß√£o pr√°tica e varia√ß√£o de par√¢metros

A varia√ß√£o da camada escondida ajuda na detec√ß√£o de padr√µes, mas tem que tomar cuidado com o overfitting. Esses n√∫meros representam quantos neur√¥nios em cada camada escondida, ent√£o n√∫meros agregados quer dizer mais de uma camada.

Quanto mais camadas, maior a chance de aprender fun√ß√µes n√£o lineares complexas. A diminui√ß√£o de valores √© para criar um fun√≠l for√ßando o algoritmo a resumir as informa√ß√µes. Quanto mais camadas, mais dados s√£o requeridos.

```python
'hidden_layer_sizes': [
    (200,), (100,), (50,), (200,100), (200,100,50), (200,100,50,25)
]
```

As fun√ß√µes de ativa√ß√£o dos perceptrons em redes neurais n√£o se limitam apenas no bin√°rio zero e um (aquelas chamadas de fun√ß√£o degrau). Essas fun√ß√µes retornam valores cont√≠nuos. A fun√ß√£o `relu` √© a mais usada por ser eficiente e funcionar como `max(0, x)`. J√° a `tanh` suaviza os dados retornando entre -1 e 1.

```python
'activation': ['relu', 'tanh']
```

Os par√¢metros `solver` + `learning_rate_init` + `alpha` servem para a atualiza√ß√£o dos pesos.

* Solver: algoritmo usado para fazer o gradiente descendente, definindo como o erro √© corrigido.&#x20;
  * `'adam'`: adaptativo, ajusta o aprendizado ao longo do tempo, muito usado hoje.
  * `'sgd'`: gradiente estoc√°stico puro. Mais lento, mas mais simples e te d√° mais controle.
* Alpha: n√£o varia, deixando um valor bem baixo que faz penalidades leves para os pesos.
* Learning rate init: √â o tamanho dos passos dados para o gradiente descendente. Lembrando que existe aquele dilema entre valores altos e baixos.

```python
'solver': ['adam', 'sgd'],
'alpha': [0.0001],
'learning_rate_init': [0.001, 0.01, 0.1]
```

Podemos definir a cada quantas amostras de treino o algoritmo vai fazer a atualiza√ß√£o dos pesos. O algoritmo passa por todas as camadas e faz todo o seu percurso, mas usando a quantidade definida de amostras em `batch_size`. Quanto maior, mais est√°vel.

```python
'batch_size': [8, 16, 32, 64]
```

Por fim, algo j√° visto em valida√ß√£o, o embaralhamento de dados a [cada √©poca](#user-content-fn-5)[^5] para evitar decorar ordem de dados com shuffle. N√£o embaralhar pode ser bom para dados que podem ser afetados por sequ√™ncias temporais.

```python
'shuffle': [True, False]
```

#### Aplica√ß√£o do resto do algoritmo

Define o m√°ximo de √©pocas. 1000 significa que o modelo pode passar at√© mil vezes pelos dados de treino, mas se convergir antes, o modelo vai parar. Convergir significa que em X itera√ß√µes (podendo ser definido no par√¢metro n\_iter\_no\_change) n√£o ter melhora significativa no F1-score, o modelo √© interrompido automaticamente.&#x20;

```python
mlp = MLPClassifier(
    max_iter=1000,
    early_stopping=True,
    random_state=42
)

grid_search_mlp = GridSearchCV(
    estimator=mlp,
    param_grid=param_grid_mlp,
    scoring='f1_weighted',
    cv=5,      # usa valida√ß√£o cruzada com 5 folds para avaliar a performance
    verbose=1, # usa todos os n√∫cleos do processador
    n_jobs=-1  # imprime progresso no terminal
)
grid_search_mlp.fit(X_train, y_train)
```

[^1]: Retorna zero ou um.

[^2]: Sinal/dendrito do neur√¥nio, que √© constantemente igual a 1 e estar√° associado a um    &#x20;peso ùëäb.

[^3]: Colunas da base de dados sem contar o r√≥tulo.

[^4]: Os tipos de ativa√ß√£o s√£o especificados adiante. Cada um deles √© usado com um prop√≥sito diferente, por isso fica dif√≠cil definir certamente.

[^5]: Ciclo completo de treino.
